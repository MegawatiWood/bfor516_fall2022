{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "836e6705-e768-4ae1-ae1f-6c97682cd4b1",
   "metadata": {},
   "source": [
    "# Lab 10: Text Processing\n",
    "\n",
    "\n",
    "Todayâ€™s data contains excerpts from high-profile criminal trials.\n",
    "Already cleaned and formatted into a CSV.\n",
    "\n",
    "[Data Description](http://web.eecs.umich.edu/~mihalcea/papers/perezrosas.icmi15.pdf)\n",
    "[Download Page](https://lit.eecs.umich.edu/deceptiondetection/)\n",
    "\n",
    "# Warm-Up Exercise\n",
    "First, we will go through a simple practice exercise in class. See the course\n",
    "Github page after class for the completed code if you were not able to attend.\n",
    "\n",
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3126aee7-ddd8-412b-8ced-bb6539b65886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec6729c-2cca-43e8-a51b-b12d52399ae7",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c1747-143c-4752-b5d2-81508d8a9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data = pd.read_csv('data/trial_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7888b253-d5db-4453-a07e-26d7a9a2da5c",
   "metadata": {},
   "source": [
    "# Word Counts\n",
    "One of the simplest forms of text analysis is to count words. Counting words, however, can be performed many ways.\n",
    "You could use the `.str.split().str.len()` method from the warm-up. We can also use the NLTK *tokenizer*, \n",
    "which breaks down a string into tokens (usually words). \n",
    "\n",
    "First, let's us an example from [StackOverflow](https://stackoverflow.com/questions/10677020/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f485b-12ab-4f05-a308-773f8fc15a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If the code below gives you a LookupError, you will need to download an extra NLTK library. \n",
    "To this, just run the following two lines. You only need to do this ONCE!\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"This is my text. It includes commas, question marks? and other stuff. Acronyms, like U.S. or Dr. aren't easy to handle.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad65344d-0379-44bb-9dc1-159efc5acdb9",
   "metadata": {},
   "source": [
    "Explore the output of this command. What do you notice?\n",
    "\n",
    "For our dataset, we just need to apply this function to the text column. We will do this with `.apply()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dbb3a2-5a9d-43a0-ac84-64f7397061a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data['words'] = trial_data['transcript'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55265309",
   "metadata": {},
   "source": [
    "Next, remove the punctuation tokens. We will do/have done this in the warmup exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "trial_data['words_only'] = trial_data['words'].apply(lambda x: [word for word in x if word not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4681168-3884-4592-991b-fbd9f0b8bf45",
   "metadata": {},
   "source": [
    "Look at this dataframe. It now has a column where each row contains a list of words. \n",
    "Next, apply `len` to the `'words'` column to get the total word count for each row. `len` \n",
    "counts the number of elements in a list.\n",
    "\n",
    "If you compare the results from this method to word counts using the technique from the warmup, you will notice\n",
    "slight differences. This is common in text analysis. There are many ways that people count words, and it\n",
    "depends on how people handle punctuation, abbreviation, and acronyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538b552-63e9-4df8-9514-5c84025da2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data['word_count_nltk'] = trial_data['words_only'].apply(len)\n",
    "trial_data['word_count_nltk'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a8520-1c46-4d4c-b3b8-36d80a0d85d7",
   "metadata": {},
   "source": [
    "# Sentiment\n",
    "Sentiment analysis is extremely common in text analytics. The goal of sentiment analysis\n",
    "is to determine how positive or negative (or neutral) a passage of text is. Like word counting,\n",
    "there are many ways to do this. We will use the most popular method today, \n",
    "[VADER](https://github.com/cjhutto/vaderSentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96852369-0c4f-48ed-9171-3a3252c77317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk_sentiment = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af80fd-b826-4bd1-9124-78280b7362cd",
   "metadata": {},
   "source": [
    "## Get polarity scores\n",
    "Polarity scores are positve, negative, neutral, and compound (aka overall sentiment). These\n",
    "dimensions are important, since a sentence can have both positive and negative affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77bac25-952c-4a6d-b28d-568411d66db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_sent = trial_data['transcript'].apply(lambda x: nltk_sentiment.polarity_scores(x))\n",
    "full_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2c263-7e6e-4575-be61-839a43307143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the compound sentiment in a column\n",
    "trial_data['sentiment'] = full_sent.apply(lambda x: x['compound'])\n",
    "print(trial_data['sentiment'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121f1f5e-1745-44e2-b87d-280e7bee8345",
   "metadata": {},
   "source": [
    "## View the distribution of sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb15a3-7dcb-44d0-b6a9-e3c42e958175",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data['sentiment'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a761977-2a5e-4c37-ab07-be96c0beb4d1",
   "metadata": {},
   "source": [
    "# Predictive Analysis\n",
    "Let's see if we can predict when someone is lying vs. telling the truth (`outcome`) using the quantity of words and \n",
    "the sentement of their statements (`pred_vars`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3816d-aaa8-4839-a054-7d396fd154bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vars = ['word_count_nltk', 'sentiment']\n",
    "\n",
    "# define the dependent variable here, so we don't have to edit our later code\n",
    "outcome = 'condition'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e48507-716e-495e-8ee1-856c59f13967",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We are going to follow the same steps for classification that we have covered all semester. Much of this\n",
    "code is copy/paste from previous weeks (with minor changes).\n",
    "\n",
    "The steps are:\n",
    "1. Train/test split\n",
    "2. Fit several classifiers (using cross validation & parameter searching)\n",
    "3. Evaluate models on hold-out data (aka test data)\n",
    "4. Report Results\n",
    "\n",
    "### 1. Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66825f-c4b2-4ac6-8a09-bd2735d5e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit \n",
    "# https://stackoverflow.com/questions/54797508/how-to-generate-a-train-test-split-based-on-a-group-id\n",
    "\n",
    "splitter = GroupShuffleSplit(test_size=.20, n_splits=2)\n",
    "split = splitter.split(trial_data, groups=trial_data['name'])\n",
    "train_inds, test_inds = next(split)\n",
    "\n",
    "train = trial_data.iloc[train_inds]\n",
    "test = trial_data.iloc[test_inds]\n",
    "print(\"Rows in train:\", len(train))\n",
    "print(\"Rows in test:\", len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9c3c8e-46bc-46dd-b1f2-a41edcd7723c",
   "metadata": {},
   "source": [
    "### 2. Fit Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c4e51-4722-45aa-92e3-89b116a2ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "params = {'criterion': ['gini', 'entropy'], 'max_depth': [5, 10, 15, None]}\n",
    "\n",
    "rf_tuned = GridSearchCV(RandomForestClassifier(), param_grid=params, scoring='roc_auc')\n",
    "rf_tuned.fit(train[pred_vars], train[outcome])\n",
    "\n",
    "\n",
    "#%% Multi-layer Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "params = {'hidden_layer_sizes': [(100,), (10,10), (5,5,5)], \n",
    "          'solver': ['adam', 'lbfgs', 'sgd']}\n",
    "\n",
    "nnet_tuned = GridSearchCV(MLPClassifier(), param_grid=params, scoring='roc_auc')\n",
    "nnet_tuned.fit(train[pred_vars], train[outcome])\n",
    "\n",
    "#%% adaboost\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html#sklearn.ensemble.AdaBoostClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "params = {'n_estimators': [10, 25, 50]}\n",
    "\n",
    "ada_tuned = GridSearchCV(AdaBoostClassifier(), param_grid=params, scoring='roc_auc')\n",
    "ada_tuned.fit(train[pred_vars], train[outcome])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002d1c-baa1-492b-bc8b-322b9c9d1bdb",
   "metadata": {},
   "source": [
    "### 3. Evaluate with Hold-Out Data\n",
    "\n",
    "This code is copied from previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f5f0d-86a8-4d90-9792-f08c7e05479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "fitted = [rf_tuned, nnet_tuned, ada_tuned]\n",
    "\n",
    "result_table = pd.DataFrame(columns=['classifier_name', 'fpr','tpr','auc', \n",
    "                                     'log_loss', 'clf_report'])\n",
    "\n",
    "for clf in fitted:\n",
    "    print(clf.estimator)\n",
    "    yproba = clf.predict_proba(test[pred_vars])\n",
    "    yclass = clf.predict(test[pred_vars])\n",
    "    \n",
    "    # auc information\n",
    "    \"\"\"\n",
    "    Note that I specified the positve case here as 'truth'\n",
    "    since that is what we are trying to detect. Otherwise,\n",
    "    this line will present an error, since the classes are not\n",
    "    0 or 1, but categorical labels.\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = metrics.roc_curve(test[outcome],  yproba[:,1], pos_label='truth')\n",
    "    auc = metrics.roc_auc_score(test[outcome], yproba[:,1])\n",
    "    \n",
    "    # log loss\n",
    "    log_loss = metrics.log_loss(test[outcome], yproba[:,1])\n",
    "    \n",
    "    # add some other stats based on confusion matrix\n",
    "    clf_report = metrics.classification_report(test[outcome], yclass)\n",
    "    \n",
    "    \n",
    "    result_table = result_table.append({'classifier_name':str(clf.estimator),\n",
    "                                        'fpr':fpr, \n",
    "                                        'tpr':tpr, \n",
    "                                        'auc':auc,\n",
    "                                        'log_loss': log_loss,\n",
    "                                        'clf_report': clf_report}, ignore_index=True)\n",
    "    \n",
    "\n",
    "\n",
    "result_table.set_index('classifier_name', inplace=True)\n",
    "# print(result_table)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14,12))\n",
    "\n",
    "for i in result_table.index:\n",
    "    plt.plot(result_table.loc[i]['fpr'], \n",
    "             result_table.loc[i]['tpr'], \n",
    "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
    "    \n",
    "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
    "\n",
    "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "\n",
    "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
    "plt.legend(prop={'size':13}, loc='lower right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167ab75-fb9c-4ff7-879e-7a66356c782f",
   "metadata": {},
   "source": [
    "### 3b. Confusion Matrix Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb4b419-81f0-4e18-8215-f8b88490b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result_table.index:\n",
    "    print('\\n---- statistics for', i, \"----\\n\")\n",
    "    print(result_table.loc[i, 'clf_report'])\n",
    "    print(\"Model log loss:\", result_table.loc[i, 'log_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1012fd6f-bbcf-48d7-ab0d-a6c4adda29c9",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "1. Name at least three limitations of this data.\n",
    "2. From the results above, which model would you say performed best?\n",
    "\n",
    "## Optional Exercises\n",
    "3. With text analysis, the variables that you can construct are only limited by your imagination.\n",
    "   Try computing another measure and see if that improves the prediction results.\n",
    "   For example, you might try to count the number of times a transcription contains the use of \"I\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d3d71-c5fb-42de-84dc-0455b5dda1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
