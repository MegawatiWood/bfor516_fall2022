{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Prediction, Continued...\n",
    "In this lab, we will learn how to use machine learning \n",
    "estimators for continuous predictions. These models\n",
    "do not have the rigid assumptions of classical linear \n",
    "regression, which makes them more flexible; however,\n",
    "the fitted models are essentially a black box. This\n",
    "limits insights into the variables that contribute\n",
    "to accuracy.\n",
    "\n",
    "We will continue with the loan quality dataset. We\n",
    "will use several different machine learning algorithms\n",
    "and compare the new results with the linear regressions\n",
    "from last week.\n",
    "\n",
    "# Predicting Loan Quality\n",
    "\n",
    "One of the most imporant aspects of lending is determining the\n",
    "interest rate to give a customer. Set rates too high, and the\n",
    "customer may choose another lender. Set rates too low, and \n",
    "lender may not earn enough interest to offset defaults and other expenses.\n",
    "\n",
    "The data for this exercise comes from Lending Club, a peer-to-peer lending company.\n",
    "They facilitate loans and allow individuals to make loans or borrow money (you \n",
    "can read more about them on \n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Lending_Club).\n",
    "\n",
    "Download the loan data that is on Blackboard. This is not the newest data, \n",
    "but it has the outcomes of many loans that have reached maturity. We can use the first dataset\n",
    "to train and the second to test. You should also download the data dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "First, let's read in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = pd.read_csv('data/lendingclub_2015-2018.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsampling\n",
    "\n",
    "The size of this dataset causes model training to take a very long time. \n",
    "I will take a random subsample to speed up the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld = ld.sample(100000, random_state=516)\n",
    "ld.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount\n",
    "First, let's look at the distribution of loan amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['loan_amnt'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual Income\n",
    "Annual income is not as neatly distributed as some of the other variables. There are several observations that report income of greater than \\$1mn, and \n",
    "many who report no income at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['annual_inc'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rescaling\n",
    "Some of the columns that we will use are on very different scales. For example, loan amount and annual income range from 0 to tens of thousands of dollars,\n",
    "whereas the debt-to-income (`dti`) range is much smaller. This can cause issues when fitting the models.\n",
    "\n",
    "We will transform the income variable using a log transformation. This will make the distribution closer to a bell curve. I added 1 to annual\n",
    "income, since $log(0)$ is undefined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld['log_annual_inc'] = np.log(ld['annual_inc']+1)\n",
    "ld['log_annual_inc'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Duration\n",
    "The loan duration column is formatted as a text string, and must be cleaned up for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view unique values\n",
    "ld['term'].unique()\n",
    "\n",
    "# split rows into parts\n",
    "term_split = ld['term'].str.split(' ')\n",
    "\n",
    "# view first five rows\n",
    "print(term_split[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the str function can retrieve a specific list element for all rows\n",
    "term_split.str[1]\n",
    "ld['duration'] = term_split.str[1]\n",
    "\n",
    "# add this to the dataframe\n",
    "display(ld['duration'].head())\n",
    "# this column is not in integer format. Must fix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to integer\n",
    "ld['duration'] = ld['duration'].apply(int)\n",
    "display(ld['duration'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations\n",
    "Let's run some correlations to see how some columns relate to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['int_rate', 'loan_amnt', 'installment', 'log_annual_inc', 'duration', 'fico_range_low', 'revol_util', 'dti']\n",
    "corr = ld[cols].corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "\n",
    "# ld[cols].corr() # <--- use this if you just want the table in non-graphical format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of these values, interest rate has the strongest correlations with duration and FICO score. The correlation between loan amount\n",
    "and installment size is quite high, so we should drop one of these from our subsequent analysis (highly correlated variables can \n",
    "cause issues with linear regression).\n",
    "\n",
    "Create a list of the variables to use for the prediction of interest rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_vars = ['loan_amnt', 'log_annual_inc', 'fico_range_low', 'revol_util', 'dti', 'duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows with missing values\n",
    "\n",
    "There are some rows in this dataframe that are missing values for at least one of our predictor columns.\n",
    "We will drop these from the dataframe before proceeding to avoid downstream errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before dropping rows with missing data\", len(ld))\n",
    "ld = ld.dropna(subset=pred_vars)\n",
    "print(\"after dropping rows with missing data\", len(ld))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a dataset that is cleaned and ready for analysis.\n",
    "\n",
    "# Training and testing sets\n",
    "With this dataset, the observations are ordered from newest to oldest. We can \n",
    "simulate a real-world situation by splitting our data into train and test subsets\n",
    "by their position in the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use index-based sampling since we have time series data\n",
    "train, test = train_test_split(ld, test_size=0.25, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, view the start and end dates for the two samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earliest and latest dates in train\n",
    "print(\"training data starts\\n\", train['issue_d'].head())\n",
    "print(\"training data ends\\n\", train['issue_d'].tail())\n",
    "# earliest and latest in test\n",
    "print(\"testing data starts\\n\", test['issue_d'].head())\n",
    "print(\"testing data ends\\n\", test['issue_d'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "The syntax for creating models using the `statsmodels` package\n",
    "is similar to that of `sklearn` (`sklearn` has linear regression\n",
    "functions, but it is somewhat barebones in it's model summaries\n",
    "compared to `statsmodels`). The documentation for \n",
    "ordinary least squares (OLS) regression using\n",
    "`statsmodels` is \n",
    "[here](https://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.OLS.html#statsmodels.regression.linear_model.OLS).\n",
    "\n",
    "We covered this last week. It is included here as a baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_multi = sm.OLS(train['int_rate'], train[pred_vars], hasconst=False).fit()\n",
    "reg_multi.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add additional predictors from our list from earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "There are many machine learning algorithms that have been developed for continuous prediction. \n",
    "Working with them is very similar to working with regressions. There are model parameters\n",
    "that one can adjust, and the steps to fit and evaluate models are similar. The evaluation\n",
    "for these models will be RMSE on the test data set.\n",
    "\n",
    "## Random Forest Regression\n",
    "We can use random forests to predict continuous outcomes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "rf_reg.fit(train[pred_vars], train['int_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "This is a support vector machine designed to make continuous predictions. Trying `SVR` is very slow for a sample of this size, but LinearSVR uses a different backend and is much faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svr_reg = LinearSVR()\n",
    "\n",
    "svr_reg.fit(train[pred_vars], train['int_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_reg = MLPRegressor()\n",
    "\n",
    "mlp_reg.fit(train[pred_vars], train['int_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "To evaluate our models, we will create a for loop to run through\n",
    "each of the models and generate predictions\n",
    "and evaluation of each model using RMSE.\n",
    "\n",
    "This looping process is similar to the evaluation loops we made for classification.\n",
    "If you were interested in a different statistic than RMSE, you could \n",
    "add that here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [reg_multi, rf_reg, svr_reg, mlp_reg]\n",
    "\n",
    "for reg in models:\n",
    "    \n",
    "    reg_pred = reg.predict(test[pred_vars])\n",
    "\n",
    "    reg_rmse = metrics.mean_squared_error(test['int_rate'], reg_pred, squared=False)\n",
    "    print(reg, \"RMSE:\", reg_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "We built machine learning regression models in an attempt to predict interest rates for loans from Lending Club\n",
    "using data about the loan request and borrower information. First, we cleaned and transformed the\n",
    "data, then viewed the correlations between a subset of variables. Then, we built models on\n",
    "on a training set of data. Lastly, we compared\n",
    "the models on a holdout set of data using RMSE.\n",
    "\n",
    "# Exercises\n",
    "1. Add another algorithm for regression \n",
    "   [(See this list)](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "   Compare the models again. Which performed best?\n",
    "2. In last week's lab, you were asked to add additional variables to\n",
    "   try improving the predictions. Use those variables again on\n",
    "   each of these models and evaluate. How does the RMSE change \n",
    "   with the additional predictors? Which model was best?\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa3e7337b8d36894b7a51014394139a0eba3728352dce4cced1005d81d5028b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
