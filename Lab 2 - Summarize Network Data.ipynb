{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Summarizing Network Attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In this lab, we will try to predict malicious network attacks. \n",
    "There are many different types of attacks, but for this lab we\n",
    "will only try to predict normal vs malicious.\n",
    "\n",
    "We will need to import `pandas` and `numpy` for this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "The data comes from \n",
    "[KDD Cup 1999](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html).\n",
    "The data contains several million network connections from a lab\n",
    "environment. The purpose of this data was to help build a network\n",
    "intrusion detector. \n",
    "\n",
    "The full dataset is very large, consisting of nearly 5 million rows. You may wish\n",
    "to use the 10% subset of the data while writing your code to speed up\n",
    "model training. Once your code is proper, you can remove the\n",
    "subset and instead use the entire dataset.\n",
    "\n",
    "Download the files `kddcup.data_10_percent.gz` and `kddcup.names` from the website.\n",
    "\n",
    "## Data cleaning and preprocessing\n",
    "\n",
    "The dataset does not have column names stored in the file, so we must use the `kddcup.names` file\n",
    "to label the columns. This is our first task. The file can be treated as a `csv` by using \n",
    "`:` as the delimiter (instead of `,`). The first row contains a list of the malicious types \n",
    "of traffic, so we need to skip that. The last column in the dataset contains the type of attack (or if the traffic\n",
    "is normal). We will manually add this to the end of our list using `.append()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file\n",
    "names = pd.read_csv('data/kddcup.names', header=None, delimiter=':',skiprows=1)\n",
    "\n",
    "# make column 0 into a list\n",
    "name_list = names[0].tolist()\n",
    "\n",
    "# add the last column with type\n",
    "name_list.append('type')\n",
    "\n",
    "print(name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the data file and use the column names from the `name_list` list that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks = pd.read_csv('data/kddcup.data_10_percent_corrected', names=name_list, header=None, index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic dataframe statistics\n",
    "First, let's check the first five rows using the `.head()` function. You can also view the last five rows using the `.tail()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `.describe()` function to get a summary of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing this out directly will omit some columns for wide dataframes like this. If you want to see all of the columns, an easy way is to export the stats to a `csv` and open it with Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store stats in a dataframe\n",
    "df_stats = netattacks.describe(include='all')\n",
    "# save dataframe to file\n",
    "df_stats.to_csv('output/netattack_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize by type of attack\n",
    "Now that we have loaded the data and things seem to be reasonable, let's look into the types of attacks.\n",
    "\n",
    "First, let's count the number of rows for each attack type (and normal traffic). There are several ways to compute these counts.\n",
    "Use the `print()` function to show the results of each method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first two are good if you want other stats besides count\n",
    "# e.g. mean or standard deviation\n",
    "type_counts = netattacks.groupby('type').count()\n",
    "type_means = netattacks.groupby('type').mean()\n",
    "\n",
    "# get a multi-index with multiple stats\n",
    "type_counts = netattacks.groupby('type').agg(['count', 'mean'])\n",
    "\n",
    "# cleanest for just counts\n",
    "type_counts = netattacks['type'].value_counts()\n",
    "type_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `smurf` attacks were very common in this dataset. Normal traffic makes up a relatively small amount in this scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the data\n",
    "In many cases, the distribution of the data is interesting. Does it follow a normal, bell curve distribution? Is it uniform? Multimodal?\n",
    "Histograms are often an effective and quick way to see how a column is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks['duration'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram is not particularly useful. It is likely affected by a few outliers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks['count'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations\n",
    "The next basic analysis we will run is correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netattacks['duration'].corr(netattacks['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative correlation between two variables indicates that as the values \n",
    "of one variable increase, the values of the other decrease.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the problem\n",
    "One way to approach the problem of identifying the specific origin of each type \n",
    "of traffic (i.e. `normal`, `smurf`, `satan`). This could be complex, and does \n",
    "not account for new types of attacks (this dataset was developed over 20 years \n",
    "ago--hackers have evolved a bit since then!).\n",
    "\n",
    "A logical solution would be to reduce this to a binary problem. Normal\n",
    "traffic is *good* and should be allowed on the network, and everything\n",
    "else is *bad* and should be blocked by our firewall. We will not try to \n",
    "solve this problem in this lab (tune in next week for that!), but we \n",
    "will prepare the data for this by creating a new column that labels each\n",
    "row as *good* or *bad*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.dataquest.io/blog/tutorial-add-column-pandas-dataframe-based-on-if-else-condition/\n",
    "netattacks['label'] = np.where(netattacks['type'] == 'normal.', 'good', 'bad')\n",
    "netattacks['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Exercises\n",
    "To receive credit for this lab, please answer the following questions or complete the following tasks:\n",
    "1. Can you run correlations between continuous and categorical variables? Why or why not?\n",
    "2. Run a correlation between two or more other variables in the dataset. What might you interpret from this?\n",
    "3. Summarize by protocol (`protocol_type`). Are there more *attacks* using `TCP` or `UDP`? (Hint: Group by two columns instead of one with `.group_by(['A', 'B'])`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
